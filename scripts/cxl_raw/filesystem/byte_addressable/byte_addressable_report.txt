Byte-Addressable I/O Test Report (FIO)
======================================

Test Configuration:
- Device: /dev/nvmex0n1p1
- Filesystem: ext4
- Mount Point: /mnt
- File Size: 1G
- I/O Engine: sync (buffer I/O)
- Direct I/O: No (using page cache)
- fdatasync: Yes (after each write)
- Runtime per test: 30s

Results Summary:

Block Size | Write IOPS | Write BW (KB/s) | Mean Lat (us) | 95% Lat (us) | 99% Lat (us)
-----------|------------|-----------------|---------------|--------------|-------------
8          | 22532      | 176             | 0.75          | 1.38         | 2.61        
16         | 22627      | 353             | 0.76          | 1.35         | 2.61        
32         | 21831      | 682             | 0.80          | 1.29         | 2.58        
64         | 20260      | 1266            | 0.90          | 1.74         | 2.77        
128        | 19578      | 2447            | 0.85          | 1.93         | 2.77        
256        | 15927      | 3981            | 1.06          | 2.54         | 4.32        
512        | 13938      | 6968            | 1.17          | 2.54         | 4.32        
1k         | 10912      | 10911           | 1.45          | 2.86         | 5.54        
2k         | 8158       | 16315           | 1.94          | 3.28         | 6.24        
4k         | 5687       | 22746           | 2.58          | 4.45         | 8.03        

Analysis:
- Sub-512B writes use filesystem buffer I/O with fdatasync for persistence
- Traditional NVMe SSDs must perform read-modify-write for sectors < 512B
- Performance degradation is significant for very small I/O sizes
- fdatasync after each write ensures data durability but adds latency
- CXL SSDs with native byte-addressability can bypass these limitations

Note: This test simulates the overhead of sub-sector writes on traditional
NVMe SSDs. CXL SSDs with byte-addressable support can perform these
operations natively without filesystem overhead.
